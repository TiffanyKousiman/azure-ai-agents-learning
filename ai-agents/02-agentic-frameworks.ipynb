{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://github.com/microsoft/ai-agents-for-beginners/tree/af3a8a1904991dbde4b436544f7b49904c0635d9/02-explore-agentic-frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Agent frameworks are software platforms designed to simplify the creation, deployment, and management of AI agents. These frameworks provide developers with pre-built components, abstractions, and tools that streamline the development of complex AI systems, enhancing scalability, accessibility and efficiency in building AI systems.\n",
    "\n",
    "Key capabilities enabled by AI Agent frameworks:\n",
    "- **Agent collaboration and coordination**: multiple AI agents to work together, communicate and coordinate to solve complex tasks.\n",
    "- **Task automation and management**: provide mechanisms for automating multi-step workflows, task delegation and dynamic task management among agents.\n",
    "- **Contextual understanding and adaptation**:  Equip agents with the ability to understand context, adapt to changing environments, and make decisions based on real-time information.\n",
    "\n",
    "How to quickly prototype, iterate and improve the agent's capabilities?\n",
    "- **use modular components**: SDKs like Microsoft Semantic Kernel and LangChain offer pre-built components such as AI connectors, prompt templates, and memory management.\n",
    "- **leverage collaborative tools**: design agents with specific roles and tasks, allowing them to test and refine workflows.\n",
    "- **learn in real-time**: implement feedback loops "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Frameworks:\n",
    "- **AutoGen**: Is an experimentation framework focused on leading-edge research on multi-agent systems. It is the best place to experiment and prototype sophisticated multi-agent systems.\n",
    "- **Semantic Kernel**: Is a production-ready agent library for building enterprise agentic applications. Focuses on event-driven, distributed agentic applications, enabling multiple LLMs and SLMs, tools, and single/multi-agent design patterns. \n",
    "- **Azure AI Agent Services**: Is a platform and deployment service in Azure Foundry for agents. It offers building connectivity to services support by Azure Found like Azure OpenAI, Azure AI Search, Bing Search and code execution.\n",
    "\n",
    "> üí° A great choice is to build your application in Semantic Kernel first and then use Azure AI Agent Service to deploy your agent. This approach allows you to easily persist your agents while leveraging the power to build multi-agent systems in Semantic Kernel. Semantic Kernel also has a connector in AutoGen, making it easy to use both frameworks together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use Modular Components (Semantic Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example below uses pre-built AI Connector with Semantic Kernel Python that uses auto-function calling to have the model respond to the user input. In the auto function calling process, the model determines it can invoke the `BookTravelPlugin` using the `book_flight` function, supplying the necessary arguments. Since the location and date arguments are required (as defined by the kernel function), if the model lacks either, it will dynamically prompt the user to provide them (see example below). The example shows how a pre-built parser can be used to extract key information from user input, such as the origin, destination, and date of a flight booking request, in providing a modular approach to focus on high-level logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Could you please provide me with the date of travel for your flight to New York?`\n"
     ]
    }
   ],
   "source": [
    "# Semantic Kernel Python Example\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "from typing import Annotated\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define a ChatHistory object to hold the conversation's context\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Book me a flight to New York\") # I'd like to go to New York on January 1, 2025\n",
    "\n",
    "# Define a sample plugin that contains the function to book travel\n",
    "class BookTravelPlugin:\n",
    "    \"\"\"A Sample Book Travel Plugin\"\"\"\n",
    "\n",
    "    @kernel_function(name=\"book_flight\", description=\"Book travel given location and date\")\n",
    "    async def book_flight(\n",
    "        self, date: Annotated[str, \"The date of travel\"], location: Annotated[str, \"The location to travel to\"]\n",
    "    ) -> str:\n",
    "        return f\"Travel was booked to {location} on {date}\"\n",
    "\n",
    "# Create the Kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add the sample plugin to the Kernel object\n",
    "kernel.add_plugin(BookTravelPlugin(), plugin_name=\"book_travel\")\n",
    "\n",
    "# Define the Azure OpenAI AI Connector\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=os.environ.get(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\"), \n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"), \n",
    "    endpoint=os.environ.get(\"AZURE_OPENAI_SERVICE\"),\n",
    ")\n",
    "\n",
    "# Define the request settings to configure the model with auto-function calling\n",
    "request_settings = AzureChatPromptExecutionSettings(function_choice_behavior=FunctionChoiceBehavior.Auto())\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Make the request to the model for the given chat history and request settings\n",
    "    # The Kernel contains the sample that the model will request to invoke\n",
    "    response = await chat_service.get_chat_message_content(\n",
    "        chat_history=chat_history, settings=request_settings, kernel=kernel\n",
    "    )\n",
    "    assert response is not None\n",
    "\n",
    "    \"\"\"\n",
    "    Note: In the auto function calling process, the model determines it can invoke the \n",
    "    `BookTravelPlugin` using the `book_flight` function, supplying the necessary arguments. \n",
    "    \n",
    "    For example:\n",
    "\n",
    "    \"tool_calls\": [\n",
    "        {\n",
    "            \"id\": \"call_abc123\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"BookTravelPlugin-book_flight\",\n",
    "                \"arguments\": \"{'location': 'New York', 'date': '2025-01-01'}\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    Since the location and date arguments are required (as defined by the kernel function), if the \n",
    "    model lacks either, it will prompt the user to provide them. For instance:\n",
    "\n",
    "    User: Book me a flight to New York.\n",
    "    Model: Sure, I'd love to help you book a flight. Could you please specify the date?\n",
    "    User: I want to travel on January 1, 2025.\n",
    "    Model: Your flight to New York on January 1, 2025, has been successfully booked. Safe travels!\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"`{response}`\")\n",
    "    # Example AI Model Response: `Your flight to New York on January 1, 2025, has been successfully booked. Safe travels! ‚úàÔ∏èüóΩ`\n",
    "\n",
    "    # Add the model's response to our chat history context\n",
    "    chat_history.add_assistant_message(response.content)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Leverage Collaborative Tools (AutoGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frameworks like **CrewAI**, Microsoft **AutoGen**, and **Semantic Kernel** facilitate the creation of multiple agents that can work together.\n",
    "\n",
    "In this example, we create multiple agents followed by creating a round robin schedule where they can work together to analyze data. Each agent performs a specific function and role, and the task is executed by coordinating the agents to achieve desired outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Retrieval Agent\n",
    "# Data Analysis Agent\n",
    "# Decision Making Agent\n",
    "\n",
    "agent_retrieve = AssistantAgent(\n",
    "    name=\"dataretrieval\",\n",
    "    model_client=model_client,\n",
    "    tools=[retrieve_tool],\n",
    "    system_message=\"Use tools to solve tasks.\"\n",
    ")\n",
    "\n",
    "agent_analyze = AssistantAgent(\n",
    "    name=\"dataanalysis\",\n",
    "    model_client=model_client,\n",
    "    tools=[analyze_tool],\n",
    "    system_message=\"Use tools to solve tasks.\"\n",
    ")\n",
    "\n",
    "# conversation ends when user says \"APPROVE\"\n",
    "termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)\n",
    "\n",
    "team = RoundRobinGroupChat([agent_retrieve, agent_analyze, user_proxy], termination_condition=termination)\n",
    "\n",
    "stream = team.run_stream(task=\"Analyze data\", max_turns=10)\n",
    "# Use asyncio.run(...) when running in a script.\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Azure AI Agent - Data Visualiser Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import CodeInterpreterTool\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# connect to project client\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Azure AI Agent Execution</h2><div><strong>Created agent</strong> with ID: asst_C2ucs7gORhWBImw3aZehNwik</div><div><strong>Created thread</strong> with ID: thread_cnm0FC0DEErxHyzXV1bVMdgy</div><div style='margin:15px 0; padding:10px; background-color:#f5f5f5; border-left:4px solid #007bff; border-radius:4px;'><strong>User:</strong><br><div style='margin-left:15px'>Could you please create a bar chart for the operating profit using the following data and provide the file to me? Bali: 100 Travelers, Paris: 356 Travelers, London: 900 Travelers, Tokyo: 850 Travellers</div></div><div style='color:#007bff'><i>Processing request...</i></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Azure AI Agent Execution</h2><div><strong>Created agent</strong> with ID: asst_C2ucs7gORhWBImw3aZehNwik</div><div><strong>Created thread</strong> with ID: thread_cnm0FC0DEErxHyzXV1bVMdgy</div><div style='margin:15px 0; padding:10px; background-color:#f5f5f5; border-left:4px solid #007bff; border-radius:4px;'><strong>User:</strong><br><div style='margin-left:15px'>Could you please create a bar chart for the operating profit using the following data and provide the file to me? Bali: 100 Travelers, Paris: 356 Travelers, London: 900 Travelers, Tokyo: 850 Travellers</div></div><div><strong>Run finished</strong> with status: <span style='color:red'>RunStatus.FAILED</span></div><div style='color:red'><strong>Run failed:</strong> {'code': 'rate_limit_exceeded', 'message': 'Rate limit is exceeded. Try again in 60 seconds.'}</div><div style='margin:15px 0; padding:10px; background-color:#f0f7ff; border-left:4px solid #28a745; border-radius:4px;'><strong>Assistant:</strong><br></div><div style='margin-top:10px'><i>Agent deleted after completion</i></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "async def run_agent_with_visualization():\n",
    "    html_output = \"<h2>Azure AI Agent Execution</h2>\"\n",
    "\n",
    "    with project_client:\n",
    "        # Create an instance of the CodeInterpreterTool\n",
    "        code_interpreter = CodeInterpreterTool()\n",
    "\n",
    "        # The CodeInterpreterTool needs to be included in creation of the agent\n",
    "        agent = project_client.agents.create_agent(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            name=\"my-agent\",\n",
    "            instructions=\"You are helpful agent\",\n",
    "            tools=code_interpreter.definitions,\n",
    "            tool_resources=code_interpreter.resources,\n",
    "        )\n",
    "        html_output += f\"<div><strong>Created agent</strong> with ID: {agent.id}</div>\"\n",
    "\n",
    "        # Create a thread\n",
    "        thread = project_client.agents.create_thread()\n",
    "        html_output += f\"<div><strong>Created thread</strong> with ID: {thread.id}</div>\"\n",
    "\n",
    "        # User query - display nicely\n",
    "        user_query = \"Could you please create a bar chart for the operating profit using the following data and provide the file to me? Bali: 100 Travelers, Paris: 356 Travelers, London: 900 Travelers, Tokyo: 850 Travellers\"\n",
    "        html_output += \"<div style='margin:15px 0; padding:10px; background-color:#f5f5f5; border-left:4px solid #007bff; border-radius:4px;'>\"\n",
    "        html_output += \"<strong>User:</strong><br>\"\n",
    "        html_output += f\"<div style='margin-left:15px'>{user_query}</div>\"\n",
    "        html_output += \"</div>\"\n",
    "\n",
    "        # Create a message\n",
    "        message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=user_query,\n",
    "        )\n",
    "\n",
    "        # Run the agent - show a \"processing\" message\n",
    "        display(HTML(\n",
    "            html_output + \"<div style='color:#007bff'><i>Processing request...</i></div>\"))\n",
    "\n",
    "        # Execute the run\n",
    "        run = project_client.agents.create_and_process_run(\n",
    "            thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "        # Update status\n",
    "        status_color = 'green' if run.status == 'completed' else 'red'\n",
    "        html_output += f\"<div><strong>Run finished</strong> with status: <span style='color:{status_color}'>{run.status}</span></div>\"\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            html_output += f\"<div style='color:red'><strong>Run failed:</strong> {run.last_error}</div>\"\n",
    "\n",
    "        # Get messages from the thread\n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "\n",
    "        # Format assistant response\n",
    "        html_output += \"<div style='margin:15px 0; padding:10px; background-color:#f0f7ff; border-left:4px solid #28a745; border-radius:4px;'>\"\n",
    "        html_output += \"<strong>Assistant:</strong><br>\"\n",
    "\n",
    "        # Handle messages based on the actual structure\n",
    "        # First, try to get the assistant's text responses\n",
    "        try:\n",
    "            # First approach - if messages is a list of objects with role attribute\n",
    "            assistant_msgs = [msg for msg in messages if hasattr(\n",
    "                msg, 'role') and msg.role == \"assistant\"]\n",
    "\n",
    "            if assistant_msgs:\n",
    "                last_msg = assistant_msgs[-1]\n",
    "                if hasattr(last_msg, 'content'):\n",
    "                    if isinstance(last_msg.content, list):\n",
    "                        for content_item in last_msg.content:\n",
    "                            if hasattr(content_item, 'type') and content_item.type == \"text\":\n",
    "                                html_output += f\"<div style='margin-left:15px; white-space:pre-wrap'>{content_item.text.value}</div>\"\n",
    "                    elif isinstance(last_msg.content, str):\n",
    "                        html_output += f\"<div style='margin-left:15px; white-space:pre-wrap'>{last_msg.content}</div>\"\n",
    "\n",
    "            # If no messages were found with the above approach, try a different structure\n",
    "            if not assistant_msgs:\n",
    "                # If messages is a class with attributes\n",
    "                if hasattr(messages, 'data'):\n",
    "                    for msg in messages.data:\n",
    "                        if hasattr(msg, 'role') and msg.role == \"assistant\":\n",
    "                            if hasattr(msg, 'content'):\n",
    "                                html_output += f\"<div style='margin-left:15px; white-space:pre-wrap'>{msg.content}</div>\"\n",
    "\n",
    "        except Exception as e:\n",
    "            html_output += f\"<div style='color:red'><strong>Error processing messages:</strong> {str(e)}</div>\"\n",
    "\n",
    "        html_output += \"</div>\"\n",
    "\n",
    "        # Handle image contents based on the actual structure\n",
    "        saved_images = []\n",
    "        try:\n",
    "            # Try to access image_contents as an attribute\n",
    "            if hasattr(messages, 'image_contents'):\n",
    "                for image_content in messages.image_contents:\n",
    "                    file_id = image_content.image_file.file_id\n",
    "                    file_name = f\"{file_id}_image_file.png\"\n",
    "                    project_client.agents.save_file(\n",
    "                        file_id=file_id, file_name=file_name)\n",
    "                    saved_images.append(file_name)\n",
    "                    html_output += f\"<div style='margin-top:10px'><strong>Generated Image:</strong> {file_name}</div>\"\n",
    "        except Exception as e:\n",
    "            html_output += f\"<div style='color:orange'><i>Note: No images found or error processing images</i></div>\"\n",
    "\n",
    "        # Handle file path annotations based on the actual structure\n",
    "        try:\n",
    "            # Try to access file_path_annotations as an attribute\n",
    "            if hasattr(messages, 'file_path_annotations'):\n",
    "                for file_path_annotation in messages.file_path_annotations:\n",
    "                    file_name = Path(file_path_annotation.text).name\n",
    "                    project_client.agents.save_file(\n",
    "                        file_id=file_path_annotation.file_path.file_id, file_name=file_name)\n",
    "                    html_output += \"<div style='margin:10px 0; padding:8px; background-color:#f8f9fa; border:1px solid #ddd; border-radius:4px;'>\"\n",
    "                    html_output += f\"<strong>Generated File:</strong> {file_name}<br>\"\n",
    "                    html_output += f\"<strong>Type:</strong> {file_path_annotation.type}<br>\"\n",
    "                    html_output += \"</div>\"\n",
    "        except Exception as e:\n",
    "            html_output += f\"<div style='color:orange'><i>Note: No file annotations found or error processing files</i></div>\"\n",
    "\n",
    "        # Delete the agent once done\n",
    "        project_client.agents.delete_agent(agent.id)\n",
    "        html_output += \"<div style='margin-top:10px'><i>Agent deleted after completion</i></div>\"\n",
    "\n",
    "        # Final display of all content\n",
    "        display(HTML(html_output))\n",
    "\n",
    "        # Display any saved images\n",
    "        for img_file in saved_images:\n",
    "            display(Image(img_file))\n",
    "\n",
    "# Execute the function\n",
    "await run_agent_with_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AutoGen - Trip Planning Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Github Model (`gpt-4o-mini`) for access to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the LLM client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_reason='stop' content='The capital of France is Paris.' usage=RequestUsage(prompt_tokens=14, completion_tokens=8) cached=False logprobs=None thought=None\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "client = AzureAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.\n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    credential=AzureKeyCredential(os.getenv(\"GITHUB_TOKEN\")),\n",
    "    model_info={\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"vision\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")\n",
    "\n",
    "result = await client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",       # name of the agent, useful in referencing in multi-agent workflows\n",
    "    model_client=client,    # LLM client\n",
    "    tools=[],               # any available tools agent can use to complete the task\n",
    "    system_message=\"You are a travel agent that plans great vacations\",  # metaprompt defining the task, behaviour and tone of LLM\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`on_message` method is used to update the Agent's state with the new message from the user which is `\"Plan me a great sunny vacation\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom:10px'><div style='font-weight:bold'>User:</div><div style='margin-left:20px'>Plan me a great sunny vacation</div></div><div style='margin-bottom:20px'><div style='font-weight:bold'>Assistant:</div><div style='margin-left:20px; white-space:pre-wrap'>Sure! I‚Äôd love to help you plan a sunny vacation. Here‚Äôs a suggested itinerary for a week-long getaway to Maui, Hawaii, which is known for its stunning beaches, vibrant culture, and lush scenery.\n",
       "\n",
       "### Sunny Vacation in Maui, Hawaii\n",
       "\n",
       "#### **Duration:** 7 Days\n",
       "\n",
       "---\n",
       "\n",
       "### **Day 1: Arrival in Maui**\n",
       "- **Flight:** Arrive at Kahului Airport (OGG).\n",
       "- **Accommodation:** Check into a beachfront resort in Wailea or Kaanapali.\n",
       "- **Evening:** Enjoy a welcome dinner at a local Hawaiian restaurant, like Mama‚Äôs Fish House.\n",
       "\n",
       "### **Day 2: Exploring the Beaches**\n",
       "- **Morning:** Relax at Wailea Beach or Kaanapali Beach. Enjoy swimming, sunbathing, and beach activities.\n",
       "- **Afternoon:** Take a snorkeling trip to Molokini Crater, famous for its vibrant marine life.\n",
       "- **Evening:** Watch the sunset at the beach and dine at Duke‚Äôs Beach House.\n",
       "\n",
       "### **Day 3: Road to Hana**\n",
       "- **Morning:** Drive the scenic Road to Hana. Stop at waterfalls, black sand beaches, and local stands.\n",
       "- **Highlights:** Visit Twin Falls, Wai'anapanapa State Park, and the charming town of Hana.\n",
       "- **Evening:** Return to your resort and enjoy a quiet night.\n",
       "\n",
       "### **Day 4: HaleakalƒÅ National Park**\n",
       "- **Early Morning:** Head to HaleakalƒÅ National Park for a sunrise viewing at the summit (book in advance, as permits are required).\n",
       "- **Daytime:** Explore the park‚Äôs trails and landscapes, including the Sliding Sands Trail.\n",
       "- **Evening:** Return to your hotel and dine leisurely.\n",
       "\n",
       "### **Day 5: Culture and Adventure**\n",
       "- **Morning:** Take a Hawaiian cultural class (lei making, hula dancing, or ukulele).\n",
       "- **Afternoon:** Go on a whale-watching tour if visiting during the season (December to April) or try stand-up paddleboarding at a nearby beach.\n",
       "- **Evening:** Enjoy a traditional luau, like the Old Lahaina Luau, featuring food, music, and dance.\n",
       "\n",
       "### **Day 6: Island Hopping or Relaxation**\n",
       "- **Option 1:** Take a day trip to the nearby island of Lanai or Molokai for pristine beaches and unique experiences (book a ferry in advance). \n",
       "- **Option 2:** Spend the day relaxing at the resort, indulging in a spa day or a round of golf.\n",
       "- **Evening:** Dinner at The Feast at Lele, offering a lovely sunset view and a taste of different Hawaiian islands.\n",
       "\n",
       "### **Day 7: Last Day**\n",
       "- **Morning:** Quick shopping at local markets or relax by the pool.\n",
       "- **Afternoon:** Enjoy a final beach day with water activities or simply soak up the sun.\n",
       "- **Evening:** Depart for the airport with beautiful memories and souvenirs.\n",
       "\n",
       "---\n",
       "\n",
       "### **Tips:**\n",
       "- **Best Time to Visit:** The months of April to June and September to November have great weather and fewer crowds.\n",
       "- **Rental Car:** Consider renting a car for easy transportation and to explore the island at your own pace.\n",
       "- **Pack:** Don‚Äôt forget sunscreen, swimwear, and light clothing.\n",
       "\n",
       "Let me know if you‚Äôd like adjustments or more information on specific activities!</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "async def assistant_run():\n",
    "    # Define the query\n",
    "    user_query = \"Plan me a great sunny vacation\"\n",
    "\n",
    "    # Start building HTML output\n",
    "    html_output = \"<div style='margin-bottom:10px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>User:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px'>{user_query}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Execute the agent response\n",
    "    response = await agent.on_messages(\n",
    "        [TextMessage(content=user_query, source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    # Add agent response to HTML\n",
    "    html_output += \"<div style='margin-bottom:20px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>Assistant:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px; white-space:pre-wrap'>{response.chat_message.content}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Display formatted HTML\n",
    "    display(HTML(html_output))\n",
    "\n",
    "# Run the function\n",
    "await assistant_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
