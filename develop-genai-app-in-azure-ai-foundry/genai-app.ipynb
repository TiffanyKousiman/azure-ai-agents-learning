{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://learn.microsoft.com/en-us/training/modules/ai-foundry-sdk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package installation:\n",
    "# pip install azure-ai-textanalytics azure-ai-projects azure-identity azure-ai-inference python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in environment variables from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "PROJECT_CONNECTION = os.getenv(\"PROJECT_CONNECTION\") # project connection string from overview page in Azure AI Foundry\n",
    "MODEL_DEPLOYMENT =  os.getenv(\"MODEL_DEPLOYMENT\")    # model name (gpt-4)\n",
    "API_VERSION = os.getenv(\"API_VERSION\")               # model version (2024-12-01-preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Azure AI Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core package for working with projects in the Azure AI Foundary SDK is the `Azure AI Projects` library (**AIProjectClient** class) which serves as a programmatic proxy for a project enabling us to connect to an Azure AI Foundary project and access connected resources defined within it.\n",
    "\n",
    "The package `azure-identity` is to allow for a keyless authentication using the default Azure credentials (before so need to install Azure CLI and sign into azure before running the code to set up an authenticated Azure session - see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisites**: \n",
    "1. get the **project connection string** from the Azure AI Foundry overview page.\n",
    "2. Install **Azure CLI** per the [installation instructions](https://learn.microsoft.com/en-gb/cli/azure/install-azure-cli?WT.mc_id=academic-105485-koreyst) to enable authentication. Once installed, open a terminal and run `az login` to sign in to Azure account in vscode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_connection_string = PROJECT_CONNECTION\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "      credential=DefaultAzureCredential(),\n",
    "      conn_str=project_connection_string,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Azure AI Foundry project includes **connected resources** which can be defined both at hub and project level. Each resource is connected to an external service such as Azure AI services, Azure AI search and others. To retrieve connections in python, the **AIProjectClient** object in python has a **connections** property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<azure.ai.projects.models._patch.ConnectionProperties at 0x10642fcb0>,\n",
       " <azure.ai.projects.models._patch.ConnectionProperties at 0x10649ac10>,\n",
       " <azure.ai.projects.models._patch.ConnectionProperties at 0x10649a990>,\n",
       " <azure.ai.projects.models._patch.ConnectionProperties at 0x10647f360>,\n",
       " <azure.ai.projects.models._patch.ConnectionProperties at 0x10647f950>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access a full collection of connection objects\n",
    "project_client.connections.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.ai.projects.models._patch.ConnectionProperties at 0x106455d90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get default connection of specified type (Azure AI Service)\n",
    "project_client.connections.get_default(connection_type=ConnectionType.AZURE_AI_SERVICES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a TextAnalyticsClient object for sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I hated the movie. It was so slow!\n",
      "Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "try:\n",
    "    # Get project client\n",
    "    project_connection_string = PROJECT_CONNECTION\n",
    "    project_client = AIProjectClient.from_connection_string(\n",
    "      credential=DefaultAzureCredential(),\n",
    "      conn_str=project_connection_string,\n",
    "    )\n",
    "\n",
    "    # Get the properties of the default Azure AI Services connection with credentials\n",
    "    connection = project_client.connections.get_default(\n",
    "      connection_type=ConnectionType.AZURE_AI_SERVICES,\n",
    "      include_credentials=True, \n",
    "    )\n",
    "\n",
    "    # Use the connection information to create a text analytics client\n",
    "    ai_svc_credential = AzureKeyCredential(connection.key)\n",
    "    text_analytics_client = TextAnalyticsClient(endpoint=connection.endpoint_url, credential=ai_svc_credential)\n",
    "\n",
    "    # Use the Language service to analyze some text (to infer sentiment) \n",
    "    text = \"I hated the movie. It was so slow!\"\n",
    "    sentimentAnalysis = text_analytics_client.analyze_sentiment(documents=[text])[0]\n",
    "    print(\"Text: {}\\nSentiment: {}\".format(text,sentimentAnalysis.sentiment))\n",
    "\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a chat client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite: Deploy a gpt-4 model in Azure AI Foundry Studio\n",
    "**1. Create a project at Azure AI Foundry portal at https://ai.azure.com:**\n",
    "- project name: `my-ai-project`\n",
    "- hub name: `my-ai-hub`\n",
    "- subscription: your azure subscription\n",
    "- resource group: a unique resource name (e.g. `my-ai-resources`)\n",
    "- Location: select `gpt-4` and use the recommended region.\n",
    "- connect Azure AI service or Azure OpenAI: create a new AI Services resource (`my-ai-resources`)\n",
    "- Connect Azure AI Search: skip connecting\n",
    "\n",
    "**2. Deploy a Gen AI Model**\n",
    "- In the toolbar at the top right of your Azure AI Foundry project page, use the **Preview features** icon to enable the **Deploy models to Azure AI model inference service** feature. This feature ensures your model deployment is available to the Azure AI Inference service, which youâ€™ll use in your application code.\n",
    "- **My assets** > select **Models + endpoints** > select **Deploy model** dropdown > **Deploy base model** > search for **gpt-4**\n",
    "- deploy the model with the following settings:\n",
    "    - Deployment name: gpt-4\n",
    "    - Deployment type: select default version\n",
    "    - Model version: default\n",
    "    - Connected AI resource: your azure OpenAI resource connection\n",
    "    - Tokens per Minute Rate Limit (thousands): maximum available\n",
    "    - Content filter: DefaultV2\n",
    "    - Enable dynamic quota: disabled\n",
    "\n",
    "**3. Set up application configs in .env file**\n",
    "- defining project connection string and deployment model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the shape of earth?\n",
      "The shape of Earth is best described as an oblate spheroid. This means that it is mostly spherical, but slightly flattened at the poles and bulging at the equator due to its rotation.\n"
     ]
    }
   ],
   "source": [
    "## EXAMPLE 1: SIMPLE SINGLE QUERY\n",
    "\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "try:\n",
    "    # Initialize the project client\n",
    "    project_connection_string = PROJECT_CONNECTION\n",
    "    project_client = AIProjectClient.from_connection_string(\n",
    "        credential=DefaultAzureCredential(),\n",
    "        conn_str=project_connection_string,\n",
    "    )\n",
    "\n",
    "    ## Get an Azure OpenAI chat client\n",
    "    openai_client = project_client.inference.get_azure_openai_client(api_version=API_VERSION)\n",
    "\n",
    "    # Get a chat completion based on a user-provided prompt\n",
    "    user_prompt = input(\"Enter a question:\")\n",
    "    print('Question:', user_prompt)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=MODEL_DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant that answers questions.\"},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Hello who are you?\n",
      "Hello! I'm an AI assistant here to help answer your questions and provide information on a wide range of topics. How can I assist you today?\n",
      "Question: What is the slowest walking animal on Earth?\n",
      "The slowest walking animal on Earth is the three-toed sloth. It moves at a leisurely pace of about 0.03 miles per hour on the ground. These creatures are much better adapted to life in the trees of tropical rainforests, where they spend most of their time hanging from branches and moving through the canopy.\n"
     ]
    }
   ],
   "source": [
    "## EXAMPLE 2: MULTIPLE QUERY WITH CHAT HISTORY (see file chat-app.py in the same dir)\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage, AssistantMessage\n",
    "\n",
    "def main(): \n",
    "\n",
    "    # Clear the console\n",
    "    # os.system('cls' if os.name=='nt' else 'clear')\n",
    "        \n",
    "    try: \n",
    "    \n",
    "        # Initialize the project client\n",
    "        projectClient = AIProjectClient.from_connection_string(\n",
    "            conn_str=PROJECT_CONNECTION,\n",
    "            credential=DefaultAzureCredential()\n",
    "        )\n",
    "\n",
    "        ## Get a chat client\n",
    "        chat = projectClient.inference.get_chat_completions_client()\n",
    "\n",
    "        ## Initialize prompt with system message\n",
    "        prompt=[\n",
    "         SystemMessage(\"You are a helpful AI assistant that answers questions.\")\n",
    "        ]\n",
    "\n",
    "        # Loop until the user types 'quit'\n",
    "        while True:\n",
    "            # Get input text\n",
    "            input_text = input(\"Enter the prompt (or type 'quit' to exit): \")\n",
    "            if input_text.lower() == \"quit\":\n",
    "                break\n",
    "            if len(input_text) == 0:\n",
    "                print(\"Please enter a prompt.\")\n",
    "                continue\n",
    "            print('Question:', input_text)\n",
    "            \n",
    "            # Get a chat completion\n",
    "            prompt.append(UserMessage(input_text))\n",
    "            response = chat.complete(\n",
    "                model=MODEL_DEPLOYMENT,\n",
    "                messages=prompt)\n",
    "            completion = response.choices[0].message.content\n",
    "            print(completion)\n",
    "            prompt.append(AssistantMessage(completion))\n",
    "\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
